// concurrent_queue adapter instantiation for the two-lock queue from
// [M. Michael and M. Scott, "Simple, Fast, and Practical Non-Blocking and
// Blocking Concurrent Queue Algorithms", PODC, 1996]
// Copyright (C) 2015  Anders Gidenstam
//
// This library is free software: you can redistribute it and/or modify
// it under the terms of the GNU Lesser General Public License as published
// by the Free Software Foundation, either version 3 of the License, or
// (at your option) any later version.
//
// This library is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU Lesser General Public License for more details.
//
// You should have received a copy of the GNU Lesser General Public License
// along with this program.  If not, see <http://www.gnu.org/licenses/>.
//

#ifndef __CONCURRENT_QUEUE_MSTLB_H
#define __CONCURRENT_QUEUE_MSTLB_H

#include <EXCESS/concurrent_queue>

#include <EXCESS/spinlock>

namespace excess {

// NOTE: The Lock type used MUST enforce a read/write memory barrier on lock().
template < typename T,  typename Lock = excess::locks::spinlock_TTAS_CAS >
class concurrent_queue_MSTLB
  : public concurrent_queue<T>
{
private:
  struct node_t {
    T*      value;
    node_t* next;

    node_t()
    {
      next = 0;
    }
    
    node_t(T* value)
    {
      this->value = value;
      this->next  = 0;
    }
  };

  Lock h_lock;
  node_t* head;
  volatile int padding[64/sizeof(int)];
  Lock t_lock;
  node_t* tail;

private:
  void enqueue(T* item)
  {
    node_t* node = new node_t(item);

    t_lock.lock(); // MUST enforce a write memory barrier to ensure
                   // that node->value is globally visible before the
                   // next statement.

    tail->next = node; // The linearization point of enqueue w.r.t. dequeue:s.
    tail       = node;

    t_lock.unlock();
  }

  bool try_dequeue(T*& item)
  {
    h_lock.lock();
    
    node_t* node = head;
    node_t* new_head = node->next; // May get new node before t_lock.unlock()
                                   // and, thus, may see new_head->value
                                   // uninitialized unless t_lock.lock()
                                   // enforces a write barrier for the enqueuer.
    if (!new_head) {
      h_lock.unlock();

      return false;
    }
    head = new_head;
    item = new_head->value; // Is the value really safe in weaker memory models?
                            // No, e.g. not for an acquire/release lock as
                            // new_head/node->value might not be globally
                            // visible until after t_lock.unlock().
    h_lock.unlock();

    delete node;
    return true;
  }

  bool empty()
  {
    h_lock.lock(); // Must lock to be safe and linearizable.

    node_t* head_next = head->next;
    bool empty = !head_next;

    h_lock.unlock();
    return empty;
  }

public:
  class handle // Each instance MUST be acquired and used in a single thread.
    : public concurrent_queue<T>::handle
  {
  private:
    friend concurrent_queue_MSTLB;
    concurrent_queue_MSTLB<T>* queue;

    handle(concurrent_queue_MSTLB<T>* queue)
    {
      this->queue = queue;
    }

  public:
    ~handle()
    {
      queue = 0;
    }

    void enqueue(T* item)
    {
      queue->enqueue(item);
    }

    bool try_dequeue(T*& item)
    {
      return queue->try_dequeue(item);
    }

    bool empty()
    {
      return queue->empty();
    }
  };

  concurrent_queue_MSTLB()
  {
    head = new node_t();
    tail = head;
  }

  ~concurrent_queue_MSTLB()
  {
    node_t* next;
    for (node_t* n = head; n; n = next) {
      next = n->next;
      delete n;
    }
  }

  handle* get_handle()
  {
    return new handle(this);
  }
};

}
#endif
