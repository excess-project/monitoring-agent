  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0   321      0  67465 --:--:-- --:--:-- --:--:-- 67465  0     0    0     0    0   321      0    318 --:--:--  0:00:01 --:--:--     0  0     0    0     0    0   321      0    159 --:--:--  0:00:02 --:--:--     0  0    22    0    22    0   321     10    155 --:--:--  0:00:02 --:--:--     0
mkdir: missing operand
Try `mkdir --help' for more information.
+ PROJ_DIR=/nas_home/hpcdhopp/cel_job/mv
+ BIN=/nas_home/hpcdhopp/cel_job/mv/bin/cel_benchmark
+ BIN_PAT=/nas_home/hpcdhopp/cel_job/mv/bin/cel_benchmark_PAT
+ LUSTRE_DIR=/nas_home/hpcdhopp/cel_job/mv/data
+ RUN_ATTEMPTS=50000
+ RUN_APRUN_PARM_1=' -f /nas_home/hpcdhopp/cel_job/mv/nodefile '
+ RUN_APRUN_PARM_2=' -f /nas_home/hpcdhopp/cel_job/mv/nodefile '
+ RUN_APRUN_PARM_N=' -f /nas_home/hpcdhopp/cel_job/mv/nodefile '
+ TOL_EP=1.0E-16
+ VERBOSITY=0
+ WRITE_COMM_GRAPH=0
+ USE_CRAYPAT=0
+ RUN_TEST=1
+ NUM_MASTERS_PER_NODE=2
+ NUM_MASTERS_PER_2NODES=2
+ XX=("0" "32" "64" "64" "64" "96" "128" "128" "192" "128" "192" "256" "384" "256" "384" "256" "384" "512" "768" "512")
+ YY=("0" "32" "32" "64" "64" "64" "64" "128" "128" "128" "128" "128" "128" "256" "256" "256" "256" "256" "256" "512")
+ ZZ=("0" "32" "32" "32" "64" "64" "64" "64" "64" "128" "128" "128" "128" "128" "128" "256" "256" "256" "256" "256")
+ PROCS_ARRAY=("0" "1" "2" "4" "8" "12" "16" "32" "48" "64" "96" "128" "192" "256" "384" "512" "768" "1024" "1536" "2048")
+ DX=("0" "1" "2" "2" "2" "3" "4" "4" "6" "4" "6" "8" "12" "8" "12" "8" "12" "16" "24" "16")
+ DY=("0" "1" "1" "2" "2" "2" "2" "4" "4" "4" "4" "4" "4" "8" "8" "8" "8" "8" "8" "16")
+ DZ=("0" "1" "1" "1" "2" "2" "2" "2" "2" "4" "4" "4" "4" "4" "4" "8" "8" "8" "8" "8")
+ ITER_MAX=100
+ SIZE_MUL_X=2
+ SIZE_DIV_X=1
+ SIZE_MUL_Y=2
+ SIZE_DIV_Y=1
+ SIZE_MUL_Z=2
+ SIZE_DIV_Z=1
+ RUN_CHECK_RESULT=0
+ FREQ_MODE=1
+ FREQ_IDX_START=0
+ FREQ_IDX_END=0
+ write_performance=1
+ write_profile=1
+ PREFIX=MF_overhead_hwpower_mf_plugin_papi-mf_plugin_likwid-800msXXX_25500
+ SIZE_START=1
+ SIZE_END=1
+ PROCS_START=2
+ PROCS_END=2
+ PERF_NEW=0
+ MV_ALGORITHM_ID=1
+ MV_COMMUNICATOR_ID=5
+ BENCHMARK_ID=1
+ CORE_START=10
+ CORE_END=10
+ PERF_FILE=MF_overhead_hwpower_mf_plugin_papi-mf_plugin_likwid-800msXXX_25500_MV_JACOBI_MATRIX-SCALER-DIAGONAL_mv_comm_5_mv_alg_MV_CSR_MV_COO_size_64_64x64_64x64_64_procs_2_2_freqmode_1_freq_0-0_core_10_10.dat
+ matrix_scaler=1
+ preconditioner=1
+ mv_algorithm_off_diag=3
+ PROF_FILE=MF_overhead_hwpower_mf_plugin_papi-mf_plugin_likwid-800msXXX_25500_MV_JACOBI_MATRIX-SCALER-DIAGONAL_mv_comm_5_mv_alg_MV_CSR_MV_COO_size_64_64x64_64x64_64_procs_2_2_freqmode_1_freq_0-0_core_10_10_prof.dat
+ echo 'size XX: 32 - 32'
+ echo 'size YY: 32 - 32'
+ echo 'size ZZ: 32 - 32'
+ echo procs: 2 - 2
+ cd /nas_home/hpcdhopp/cel_job/mv
+ module load mpi/mvapich2/2.2.1-gnu-4.9.2
++ /usr/bin/modulecmd bash load mpi/mvapich2/2.2.1-gnu-4.9.2
+ eval HOSTFILE=/opt/mpi/mvapich2/2.2.1-gnu-4.9.2/hostfile_mvapich ';export' 'HOSTFILE;INCLUDE=/opt/mpi/mvapich2/2.2.1-gnu-4.9.2/include' ';export' 'INCLUDE;LD_LIBRARY_PATH=/opt/mpi/mvapich2/2.2.1-gnu-4.9.2/lib:/opt/compiler/gnu/4.9.2/lib64:/opt/compiler/gnu/4.9.2/lib' ';export' 'LD_LIBRARY_PATH;LIBRARY_PATH=/opt/compiler/gnu/4.9.2/lib64:/opt/compiler/gnu/4.9.2/lib' ';export' 'LIBRARY_PATH;LOADEDMODULES=power/mf_shared/20:compiler/gnu/4.9.2:mpi/mvapich2/2.2.1-gnu-4.9.2' ';export' 'LOADEDMODULES;MANPATH=/opt/mpi/mvapich2/2.2.1-gnu-4.9.2/share/man:/opt/compiler/gnu/4.9.2/share/man:/usr/share/man' ';export' 'MANPATH;PATH=/opt/mpi/mvapich2/2.2.1-gnu-4.9.2/bin:/opt/compiler/gnu/4.9.2/bin:/opt/power/mf_shared//20/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/opt/ibutils/bin:/nas_home//hpcdhopp/bin' ';export' 'PATH;_LMFILES_=/opt/modulefiles/power/mf_shared/20:/opt/modulefiles/compiler/gnu/4.9.2:/opt/modulefiles/mpi/mvapich2/2.2.1-gnu-4.9.2' ';export' '_LMFILES_;'
++ HOSTFILE=/opt/mpi/mvapich2/2.2.1-gnu-4.9.2/hostfile_mvapich
++ export HOSTFILE
++ INCLUDE=/opt/mpi/mvapich2/2.2.1-gnu-4.9.2/include
++ export INCLUDE
++ LD_LIBRARY_PATH=/opt/mpi/mvapich2/2.2.1-gnu-4.9.2/lib:/opt/compiler/gnu/4.9.2/lib64:/opt/compiler/gnu/4.9.2/lib
++ export LD_LIBRARY_PATH
++ LIBRARY_PATH=/opt/compiler/gnu/4.9.2/lib64:/opt/compiler/gnu/4.9.2/lib
++ export LIBRARY_PATH
++ LOADEDMODULES=power/mf_shared/20:compiler/gnu/4.9.2:mpi/mvapich2/2.2.1-gnu-4.9.2
++ export LOADEDMODULES
++ MANPATH=/opt/mpi/mvapich2/2.2.1-gnu-4.9.2/share/man:/opt/compiler/gnu/4.9.2/share/man:/usr/share/man
++ export MANPATH
++ PATH=/opt/mpi/mvapich2/2.2.1-gnu-4.9.2/bin:/opt/compiler/gnu/4.9.2/bin:/opt/power/mf_shared//20/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/opt/ibutils/bin:/nas_home//hpcdhopp/bin
++ export PATH
++ _LMFILES_=/opt/modulefiles/power/mf_shared/20:/opt/modulefiles/compiler/gnu/4.9.2:/opt/modulefiles/mpi/mvapich2/2.2.1-gnu-4.9.2
++ export _LMFILES_
+ perf_file_path=/nas_home/hpcdhopp/cel_job/mv/data/MF_overhead_hwpower_mf_plugin_papi-mf_plugin_likwid-800msXXX_25500_MV_JACOBI_MATRIX-SCALER-DIAGONAL_mv_comm_5_mv_alg_MV_CSR_MV_COO_size_64_64x64_64x64_64_procs_2_2_freqmode_1_freq_0-0_core_10_10.dat
+ prof_file_path=/nas_home/hpcdhopp/cel_job/mv/data/MF_overhead_hwpower_mf_plugin_papi-mf_plugin_likwid-800msXXX_25500_MV_JACOBI_MATRIX-SCALER-DIAGONAL_mv_comm_5_mv_alg_MV_CSR_MV_COO_size_64_64x64_64x64_64_procs_2_2_freqmode_1_freq_0-0_core_10_10_prof.dat
+ '[' 0 -ge 1 ']'
++ seq 1 1
+ for j in '`seq ${SIZE_START} ${SIZE_END}`'
++ seq 2 2
+ for p in '`seq ${PROCS_START} ${PROCS_END}`'
++ seq 10 10
+ for i in '`seq ${CORE_START} ${CORE_END}`'
++ seq 0 0
+ for freq in '`seq ${FREQ_IDX_START} ${FREQ_IDX_END}`'
+ XX1=64
+ YY1=64
+ ZZ1=64
+ echo procs: 2 'threads per proc:' 10 'test id:' 1
+ echo DX: 2 DY: 1 DZ: 1 XX: 64 YY: 64 ZZ: 64 ATTEMPTS: 50000
+ echo cores: 10 - 10
+ '[' 1 -ge 1 ']'
+ sleep 3
+ case ${PROCS_ARRAY[p]} in
+ mpirun -n 2 -f /nas_home/hpcdhopp/cel_job/mv/nodefile /nas_home/hpcdhopp/cel_job/mv/bin/cel_benchmark -verbosity 0 -nx 64 -ny 64 -nz 64 -dx 2 -dy 1 -dz 1 -prefetcher 0 -increase_factor 1.1 -tests_num 1 -generatematrix 1 -iter_max 100 -eps 1.0e-12 -attempts 50000 -check_result 0 -write_matrix 0 -write_performance 1 -performance_filename /nas_home/hpcdhopp/cel_job/mv/data/MF_overhead_hwpower_mf_plugin_papi-mf_plugin_likwid-800msXXX_25500_MV_JACOBI_MATRIX-SCALER-DIAGONAL_mv_comm_5_mv_alg_MV_CSR_MV_COO_size_64_64x64_64x64_64_procs_2_2_freqmode_1_freq_0-0_core_10_10.dat -threads 10 -write_profile 1 -mv_algorithm 1 -mv_communicator 5 -benchmark_id 1 -memory_level 1 -comm_graph_dir /nas_home/hpcdhopp/cel_job/mv/data/graph/comm_group_procs_ -write_comm_graph 0 -num_masters_per_node 2 -core_offset 1 -check_result 0 -frequency_index 0 -freq_mode 1 -profile_filename /nas_home/hpcdhopp/cel_job/mv/data/MF_overhead_hwpower_mf_plugin_papi-mf_plugin_likwid-800msXXX_25500_MV_JACOBI_MATRIX-SCALER-DIAGONAL_mv_comm_5_mv_alg_MV_CSR_MV_COO_size_64_64x64_64x64_64_procs_2_2_freqmode_1_freq_0-0_core_10_10_prof.dat -mv_algorithm_off_diag 3 -preconditioner 1 -matrix_scaler 1
